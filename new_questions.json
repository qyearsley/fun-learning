{
  "singleton_pattern": {
    "question_text": "What is the main purpose of the Singleton design pattern?",
    "topic": "design_patterns",
    "answers": [
      {
        "text": "To ensure a class has only one instance with global access point",
        "correct": true,
        "response": "Correct! Singleton ensures only one instance exists and provides global access, useful for configuration managers, database connections, or logging.",
        "reward_knowledge": "design_patterns_creational"
      },
      {
        "text": "To create families of related objects without specifying concrete classes",
        "correct": false,
        "response": "That's the Abstract Factory pattern, not Singleton. Singleton focuses on limiting instantiation to one object.",
        "reward_knowledge": null
      },
      {
        "text": "To define an interface for creating objects in a superclass",
        "correct": false,
        "response": "That's the Factory Method pattern. Singleton is about ensuring single instantiation, not about creating multiple objects.",
        "reward_knowledge": null
      },
      {
        "text": "To attach additional responsibilities to objects dynamically",
        "correct": false,
        "response": "That's the Decorator pattern. Singleton is about controlling instantiation to ensure only one object exists.",
        "reward_knowledge": null
      }
    ]
  },
  "observer_pattern": {
    "question_text": "In the Observer pattern, what happens when the subject's state changes?",
    "topic": "design_patterns",
    "answers": [
      {
        "text": "All registered observers are automatically notified",
        "correct": true,
        "response": "Correct! Observer pattern implements a publish-subscribe mechanism where subjects notify all observers automatically. Perfect for event systems, UI updates, and reactive programming.",
        "reward_knowledge": "design_patterns_behavioral"
      },
      {
        "text": "Observers must poll the subject to check for changes",
        "correct": false,
        "response": "No, that would defeat the purpose. Observer pattern uses push notifications, not polling, making it more efficient.",
        "reward_knowledge": null
      },
      {
        "text": "Only the first observer in the list is notified",
        "correct": false,
        "response": "Observer pattern notifies ALL registered observers, not just one. It's a one-to-many relationship.",
        "reward_knowledge": null
      },
      {
        "text": "The subject creates new observer instances automatically",
        "correct": false,
        "response": "Observers register themselves with the subject. The subject doesn't create observers, it notifies existing ones.",
        "reward_knowledge": null
      }
    ]
  },
  "strategy_pattern": {
    "question_text": "What problem does the Strategy design pattern solve?",
    "topic": "design_patterns",
    "answers": [
      {
        "text": "It allows selecting an algorithm at runtime from a family of algorithms",
        "correct": true,
        "response": "Correct! Strategy pattern encapsulates algorithms and makes them interchangeable. Great for payment methods, sorting strategies, or compression algorithms.",
        "reward_knowledge": "design_patterns_behavioral_advanced"
      },
      {
        "text": "It provides a simplified interface to a complex subsystem",
        "correct": false,
        "response": "That's the Facade pattern. Strategy is about making algorithms interchangeable, not about simplifying interfaces.",
        "reward_knowledge": null
      },
      {
        "text": "It converts the interface of a class into another interface clients expect",
        "correct": false,
        "response": "That's the Adapter pattern. Strategy focuses on encapsulating and selecting algorithms, not interface conversion.",
        "reward_knowledge": null
      },
      {
        "text": "It defines a skeleton of an algorithm, deferring steps to subclasses",
        "correct": false,
        "response": "That's the Template Method pattern. Strategy encapsulates entire algorithms, not just algorithm steps.",
        "reward_knowledge": null
      }
    ]
  },
  "factory_pattern": {
    "question_text": "What's the key advantage of the Factory pattern over direct object construction?",
    "topic": "design_patterns",
    "answers": [
      {
        "text": "It decouples object creation from usage, allowing flexibility",
        "correct": true,
        "response": "Correct! Factory pattern centralizes object creation, making it easy to change implementations, add new types, or inject dependencies without changing client code.",
        "reward_knowledge": "design_patterns_creational_advanced"
      },
      {
        "text": "It makes object creation faster and more efficient",
        "correct": false,
        "response": "Factory pattern isn't about performance. It's about flexibility and maintainability through decoupling.",
        "reward_knowledge": null
      },
      {
        "text": "It automatically prevents memory leaks",
        "correct": false,
        "response": "Factory pattern doesn't directly address memory management. Its benefit is in decoupling creation logic.",
        "reward_knowledge": null
      },
      {
        "text": "It guarantees thread-safety for all objects",
        "correct": false,
        "response": "Factory pattern doesn't inherently provide thread-safety. That requires additional synchronization mechanisms.",
        "reward_knowledge": null
      }
    ]
  },
  "tdd_cycle": {
    "question_text": "What is the correct order of the TDD (Test-Driven Development) cycle?",
    "topic": "testing",
    "answers": [
      {
        "text": "Red (failing test) → Green (make it pass) → Refactor",
        "correct": true,
        "response": "Correct! TDD follows Red-Green-Refactor: write a failing test first, implement minimal code to pass it, then refactor while keeping tests green.",
        "reward_knowledge": "tdd_methodology"
      },
      {
        "text": "Write code → Write tests → Debug",
        "correct": false,
        "response": "That's traditional testing, not TDD. TDD writes tests BEFORE implementation, driving design from requirements.",
        "reward_knowledge": null
      },
      {
        "text": "Design → Implement → Test → Deploy",
        "correct": false,
        "response": "That's a waterfall approach. TDD is iterative with very short cycles: test-first, then implement.",
        "reward_knowledge": null
      },
      {
        "text": "Refactor → Write test → Implement",
        "correct": false,
        "response": "Close, but the order is wrong. TDD starts with a failing test (Red), then implements (Green), then refactors.",
        "reward_knowledge": null
      }
    ]
  },
  "mocking_vs_stubs": {
    "question_text": "What's the key difference between mocks and stubs in testing?",
    "topic": "testing",
    "answers": [
      {
        "text": "Mocks verify behavior (calls made), stubs just provide responses",
        "correct": true,
        "response": "Correct! Mocks assert that specific methods were called with specific arguments. Stubs just return canned responses. Mocks test interaction, stubs isolate dependencies.",
        "reward_knowledge": "test_doubles"
      },
      {
        "text": "Stubs are for unit tests, mocks are for integration tests",
        "correct": false,
        "response": "Both can be used in unit tests. The difference is behavior verification (mocks) vs state verification (stubs).",
        "reward_knowledge": null
      },
      {
        "text": "Mocks are slower but more accurate than stubs",
        "correct": false,
        "response": "Performance isn't the distinction. Mocks verify interactions happened; stubs provide data without verification.",
        "reward_knowledge": null
      },
      {
        "text": "They are the same thing, just different terminology",
        "correct": false,
        "response": "No, they're distinct! Mocks verify behavior (was this method called?), stubs just return values.",
        "reward_knowledge": null
      }
    ]
  },
  "test_pyramid": {
    "question_text": "In the test pyramid, which layer should have the most tests?",
    "topic": "testing",
    "answers": [
      {
        "text": "Unit tests (bottom layer)",
        "correct": true,
        "response": "Correct! The test pyramid has many fast unit tests at the bottom, fewer integration tests in the middle, and few slow E2E tests at the top. Fast feedback is key!",
        "reward_knowledge": "testing_strategy"
      },
      {
        "text": "Integration tests (middle layer)",
        "correct": false,
        "response": "No, integration tests should be fewer than unit tests but more than E2E. They're slower and harder to maintain.",
        "reward_knowledge": null
      },
      {
        "text": "End-to-end tests (top layer)",
        "correct": false,
        "response": "E2E tests should be the fewest! They're slow, brittle, and expensive. Focus on fast unit tests for most coverage.",
        "reward_knowledge": null
      },
      {
        "text": "All layers should have equal numbers of tests",
        "correct": false,
        "response": "That's the ice cream cone anti-pattern! Unit tests should vastly outnumber integration and E2E tests.",
        "reward_knowledge": null
      }
    ]
  },
  "load_balancing": {
    "question_text": "Which load balancing algorithm is best when backend servers have different capacities?",
    "topic": "system_design",
    "answers": [
      {
        "text": "Weighted round-robin",
        "correct": true,
        "response": "Correct! Weighted round-robin assigns more requests to more powerful servers. Servers with higher capacity get proportionally more traffic.",
        "reward_knowledge": "load_balancing"
      },
      {
        "text": "Simple round-robin",
        "correct": false,
        "response": "Simple round-robin treats all servers equally, which wastes capacity if servers have different specs. Use weighted instead.",
        "reward_knowledge": null
      },
      {
        "text": "Random selection",
        "correct": false,
        "response": "Random selection doesn't account for server capacity differences. It could overload weak servers and underutilize strong ones.",
        "reward_knowledge": null
      },
      {
        "text": "Consistent hashing",
        "correct": false,
        "response": "Consistent hashing is for distributed caching/sharding, not for balancing loads across servers of different capacities.",
        "reward_knowledge": null
      }
    ]
  },
  "caching_strategy": {
    "question_text": "What's the difference between write-through and write-back caching?",
    "topic": "system_design",
    "answers": [
      {
        "text": "Write-through writes to cache and DB immediately; write-back writes to cache first, DB later",
        "correct": true,
        "response": "Correct! Write-through is safer (no data loss) but slower. Write-back is faster but risks data loss if cache fails before writeback. Choose based on consistency needs!",
        "reward_knowledge": "caching_strategies"
      },
      {
        "text": "Write-through is for reads; write-back is for writes",
        "correct": false,
        "response": "Both are write strategies! Write-through synchronously updates DB, write-back asynchronously updates DB later.",
        "reward_knowledge": null
      },
      {
        "text": "Write-back requires more memory than write-through",
        "correct": false,
        "response": "Memory isn't the key difference. The difference is WHEN the database is updated: immediately (through) or deferred (back).",
        "reward_knowledge": null
      },
      {
        "text": "They are the same, just different names",
        "correct": false,
        "response": "Very different! Write-through is synchronous and safe. Write-back is asynchronous and faster but can lose data.",
        "reward_knowledge": null
      }
    ]
  },
  "microservices_vs_monolith": {
    "question_text": "What's a key advantage of microservices over a monolithic architecture?",
    "topic": "system_design",
    "answers": [
      {
        "text": "Independent deployment and scaling of individual services",
        "correct": true,
        "response": "Correct! Microservices allow teams to deploy and scale services independently. Update payments without redeploying the entire app. Great for large teams and rapid iteration.",
        "reward_knowledge": "microservices_architecture"
      },
      {
        "text": "Microservices are always faster than monoliths",
        "correct": false,
        "response": "Actually, microservices can be slower due to network overhead between services. The advantage is flexibility, not raw speed.",
        "reward_knowledge": null
      },
      {
        "text": "Microservices eliminate the need for databases",
        "correct": false,
        "response": "Microservices still need data storage! They typically use database-per-service, not eliminate databases.",
        "reward_knowledge": null
      },
      {
        "text": "Microservices are simpler to develop and debug",
        "correct": false,
        "response": "Actually the opposite! Microservices add complexity (distributed systems, network failures, data consistency). Use when the benefits outweigh the complexity.",
        "reward_knowledge": null
      }
    ]
  },
  "database_sharding": {
    "question_text": "What is database sharding?",
    "topic": "system_design",
    "answers": [
      {
        "text": "Horizontally partitioning data across multiple database instances",
        "correct": true,
        "response": "Correct! Sharding splits data by rows across multiple DBs (e.g., users 1-1M on shard1, 1M-2M on shard2). Enables massive scale but adds complexity for cross-shard queries.",
        "reward_knowledge": "database_scaling"
      },
      {
        "text": "Creating read replicas for better read performance",
        "correct": false,
        "response": "That's replication, not sharding. Sharding partitions data; replication copies it. Both are scaling strategies but solve different problems.",
        "reward_knowledge": null
      },
      {
        "text": "Vertically splitting tables by columns into separate databases",
        "correct": false,
        "response": "That's vertical partitioning. Sharding is horizontal partitioning (splitting rows), not columns.",
        "reward_knowledge": null
      },
      {
        "text": "Caching database queries to reduce load",
        "correct": false,
        "response": "That's query caching. Sharding is about distributing data across multiple database servers to handle more data and traffic.",
        "reward_knowledge": null
      }
    ]
  },
  "api_rate_limiting": {
    "question_text": "What's the primary purpose of API rate limiting?",
    "topic": "system_design",
    "answers": [
      {
        "text": "Prevent abuse and ensure fair resource allocation across clients",
        "correct": true,
        "response": "Correct! Rate limiting protects your API from abuse, DDoS attacks, and ensures fair usage. Common strategies: token bucket, leaky bucket, fixed/sliding window.",
        "reward_knowledge": "api_design"
      },
      {
        "text": "Make APIs faster by reducing total request volume",
        "correct": false,
        "response": "Rate limiting doesn't make individual requests faster. It protects infrastructure from overload and ensures fairness.",
        "reward_knowledge": null
      },
      {
        "text": "Authenticate users before allowing API access",
        "correct": false,
        "response": "That's authentication, not rate limiting. Rate limiting controls request frequency, not identity verification.",
        "reward_knowledge": null
      },
      {
        "text": "Automatically scale servers based on demand",
        "correct": false,
        "response": "That's auto-scaling. Rate limiting controls request rates to prevent overload, not provision resources.",
        "reward_knowledge": null
      }
    ]
  },
  "docker_vs_vm": {
    "question_text": "What's a key difference between Docker containers and virtual machines?",
    "topic": "devops",
    "answers": [
      {
        "text": "Containers share the host OS kernel; VMs include a full OS",
        "correct": true,
        "response": "Correct! Containers are lightweight (MBs, start in seconds) by sharing the kernel. VMs include a full OS (GBs, start in minutes). Containers are faster but less isolated.",
        "reward_knowledge": "containerization"
      },
      {
        "text": "VMs are faster to start than containers",
        "correct": false,
        "response": "Opposite! Containers start in seconds; VMs take minutes. Containers don't boot an OS, they just start processes.",
        "reward_knowledge": null
      },
      {
        "text": "Containers provide better security isolation than VMs",
        "correct": false,
        "response": "Actually VMs provide stronger isolation since they don't share the kernel. Containers share the kernel, which can be a security risk.",
        "reward_knowledge": null
      },
      {
        "text": "Docker can only run Linux applications",
        "correct": false,
        "response": "Docker can run Linux, Windows, and Mac containers (with appropriate host OS). The OS-sharing principle applies regardless of platform.",
        "reward_knowledge": null
      }
    ]
  },
  "kubernetes_pods": {
    "question_text": "What is a Kubernetes Pod?",
    "topic": "devops",
    "answers": [
      {
        "text": "The smallest deployable unit, containing one or more containers",
        "correct": true,
        "response": "Correct! A Pod wraps containers that need to work together, sharing network/storage. Pods are ephemeral and managed by higher-level controllers like Deployments.",
        "reward_knowledge": "kubernetes"
      },
      {
        "text": "A cluster of multiple Kubernetes nodes",
        "correct": false,
        "response": "That's a Kubernetes cluster. A Pod is much smaller: the smallest unit containing containers.",
        "reward_knowledge": null
      },
      {
        "text": "A single Docker container running on Kubernetes",
        "correct": false,
        "response": "Close, but Pods can contain multiple containers, not just one. They share the same network namespace.",
        "reward_knowledge": null
      },
      {
        "text": "The control plane that manages worker nodes",
        "correct": false,
        "response": "That's the Kubernetes control plane (master nodes). Pods are workload units that run on worker nodes.",
        "reward_knowledge": null
      }
    ]
  },
  "blue_green_deployment": {
    "question_text": "How does blue-green deployment minimize downtime?",
    "topic": "devops",
    "answers": [
      {
        "text": "It maintains two identical environments and switches traffic between them",
        "correct": true,
        "response": "Correct! Blue (old) and green (new) environments run in parallel. Deploy to green, test it, then switch traffic instantly. Rollback is just switching back. Zero downtime!",
        "reward_knowledge": "deployment_strategies"
      },
      {
        "text": "It gradually rolls out changes to a percentage of users",
        "correct": false,
        "response": "That's canary deployment. Blue-green switches all traffic at once between two environments.",
        "reward_knowledge": null
      },
      {
        "text": "It deploys updates to servers one at a time",
        "correct": false,
        "response": "That's rolling deployment. Blue-green maintains full duplicate environments and switches traffic instantly.",
        "reward_knowledge": null
      },
      {
        "text": "It automatically tests code before deploying to production",
        "correct": false,
        "response": "That's CI/CD pipeline testing. Blue-green is about traffic switching between environments, not testing.",
        "reward_knowledge": null
      }
    ]
  },
  "ci_cd_pipeline": {
    "question_text": "What's the key difference between Continuous Integration (CI) and Continuous Deployment (CD)?",
    "topic": "devops",
    "answers": [
      {
        "text": "CI merges code frequently and runs tests; CD automatically deploys to production",
        "correct": true,
        "response": "Correct! CI ensures code integrates cleanly with automated tests. CD takes it further by automatically deploying passing builds to production. CD requires excellent testing confidence!",
        "reward_knowledge": "ci_cd"
      },
      {
        "text": "CI is for development; CD is for operations teams",
        "correct": false,
        "response": "Both are DevOps practices used by the whole team. CI focuses on integration/testing; CD focuses on automated deployment.",
        "reward_knowledge": null
      },
      {
        "text": "CI requires Docker; CD requires Kubernetes",
        "correct": false,
        "response": "Neither requires specific tools. CI/CD are practices, not tools. You can implement them with various technologies.",
        "reward_knowledge": null
      },
      {
        "text": "CD is just faster CI",
        "correct": false,
        "response": "CD extends CI by adding automated deployment. CI = integrate + test. CD = integrate + test + deploy automatically.",
        "reward_knowledge": null
      }
    ]
  },
  "decision_tree_splits": {
    "question_text": "In decision trees, what criterion is commonly used to decide how to split nodes?",
    "topic": "machine_learning",
    "answers": [
      {
        "text": "Information gain or Gini impurity",
        "correct": true,
        "response": "Correct! Information gain (based on entropy) and Gini impurity both measure how well a split separates classes. The split that maximizes separation is chosen. ID3 uses info gain, CART uses Gini.",
        "reward_knowledge": "decision_trees"
      },
      {
        "text": "Gradient descent on the loss function",
        "correct": false,
        "response": "Gradient descent is for neural networks, not decision trees. Trees use greedy splitting based on information gain or Gini.",
        "reward_knowledge": null
      },
      {
        "text": "Random selection of features",
        "correct": false,
        "response": "Random forests use random feature subsets, but individual trees still choose the best split within that subset using info gain/Gini.",
        "reward_knowledge": null
      },
      {
        "text": "Cross-validation error",
        "correct": false,
        "response": "Cross-validation evaluates the final model, not individual splits. Splits are chosen greedily based on purity measures.",
        "reward_knowledge": null
      }
    ]
  },
  "activation_functions": {
    "question_text": "Why is ReLU (Rectified Linear Unit) preferred over sigmoid in deep neural networks?",
    "topic": "machine_learning",
    "answers": [
      {
        "text": "ReLU avoids vanishing gradient problem and is computationally faster",
        "correct": true,
        "response": "Correct! ReLU(x) = max(0,x) has gradient 1 for positive values (no vanishing gradient) and is just a comparison (vs expensive exp in sigmoid). Enables training deeper networks!",
        "reward_knowledge": "neural_networks_advanced"
      },
      {
        "text": "ReLU always outputs values between 0 and 1",
        "correct": false,
        "response": "That's sigmoid! ReLU outputs 0 for negative inputs and x for positive (unbounded). This prevents gradient vanishing.",
        "reward_knowledge": null
      },
      {
        "text": "ReLU is differentiable everywhere",
        "correct": false,
        "response": "ReLU is not differentiable at x=0 (though we use subgradient). Its benefit is avoiding vanishing gradients, not perfect differentiability.",
        "reward_knowledge": null
      },
      {
        "text": "ReLU guarantees no overfitting",
        "correct": false,
        "response": "No activation function prevents overfitting. ReLU's benefits are faster training and avoiding vanishing gradients.",
        "reward_knowledge": null
      }
    ]
  },
  "svm_kernel_trick": {
    "question_text": "What does the kernel trick enable in Support Vector Machines (SVM)?",
    "topic": "machine_learning",
    "answers": [
      {
        "text": "It allows SVM to learn non-linear decision boundaries without explicitly computing high-dimensional features",
        "correct": true,
        "response": "Correct! Kernel trick (e.g., RBF kernel) implicitly maps data to high dimensions where it's linearly separable, without the computational cost. Elegant math: K(x,y) = φ(x)·φ(y)!",
        "reward_knowledge": "svm"
      },
      {
        "text": "It speeds up training by using fewer support vectors",
        "correct": false,
        "response": "Kernel trick is about handling non-linearity, not reducing support vectors. The number of SVs depends on the data.",
        "reward_knowledge": null
      },
      {
        "text": "It automatically prevents overfitting in SVM",
        "correct": false,
        "response": "Kernel trick enables non-linear boundaries but doesn't prevent overfitting. You still need regularization (C parameter).",
        "reward_knowledge": null
      },
      {
        "text": "It converts SVM into a neural network",
        "correct": false,
        "response": "SVM and neural networks are different algorithms. Kernel trick is specific to SVM for handling non-linearity.",
        "reward_knowledge": null
      }
    ]
  },
  "transformer_attention": {
    "question_text": "What is the key innovation of the attention mechanism in Transformers?",
    "topic": "machine_learning",
    "answers": [
      {
        "text": "It allows the model to focus on relevant parts of the input when processing each token",
        "correct": true,
        "response": "Correct! Attention computes weighted relationships between all input tokens. 'The animal didn't cross the street because it was too tired' - 'it' attends strongly to 'animal'. Revolutionized NLP!",
        "reward_knowledge": "transformers"
      },
      {
        "text": "It eliminates the need for training data",
        "correct": false,
        "response": "Transformers still need training data! Attention is about dynamically weighting input relationships, not unsupervised learning.",
        "reward_knowledge": null
      },
      {
        "text": "It makes models smaller and faster than RNNs",
        "correct": false,
        "response": "Transformers are often LARGER than RNNs! Their advantage is parallelization and better long-range dependencies, not size.",
        "reward_knowledge": null
      },
      {
        "text": "It removes the need for backpropagation",
        "correct": false,
        "response": "Transformers still use backpropagation for training. Attention is a layer type, not a training algorithm.",
        "reward_knowledge": null
      }
    ]
  },
  "regularization_ml": {
    "question_text": "How does dropout regularization help prevent overfitting in neural networks?",
    "topic": "machine_learning",
    "answers": [
      {
        "text": "It randomly disables neurons during training, forcing the network to learn robust features",
        "correct": true,
        "response": "Correct! Dropout randomly drops neurons (e.g., 50% probability) each training step. This prevents co-adaptation and forces redundant representations. Like training an ensemble! Turn off during inference.",
        "reward_knowledge": "ml_regularization"
      },
      {
        "text": "It reduces the number of layers in the network",
        "correct": false,
        "response": "Dropout doesn't change architecture. It temporarily disables random neurons during training to prevent overfitting.",
        "reward_knowledge": null
      },
      {
        "text": "It stops training when validation error increases",
        "correct": false,
        "response": "That's early stopping, not dropout. Both prevent overfitting but in different ways.",
        "reward_knowledge": null
      },
      {
        "text": "It adds noise to the training data",
        "correct": false,
        "response": "Data augmentation adds noise to data. Dropout adds noise to the model by disabling neurons. Both help regularization but differently.",
        "reward_knowledge": null
      }
    ]
  }
}
